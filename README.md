# Awesome Embodied AI  

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)  
[![GitHub stars](https://img.shields.io/github/stars/TinyEmbodiedAI/awesome-embodied-ai.svg)](https://github.com/TinyEmbodiedAI/awesome-embodied-ai/stargazers)  
[![GitHub forks](https://img.shields.io/github/forks/TinyEmbodiedAI/awesome-embodied-ai.svg)](https://github.com/TinyEmbodiedAI/awesome-embodied-ai/network)  
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)  
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)  

A curated list of awesome Embodied AI resources, frameworks, libraries, papers, and projects. Embodied AI focuses on developing intelligent systems that learn through physical or virtual interaction with their environment.  

## Contents  

- [Introduction](#introduction)  
- [Getting Started](#getting-started)  
- [Papers](#papers)  
- [Software & Tools](#software--tools)  
- [Datasets](#datasets)  
- [Courses & Tutorials](#courses--tutorials)  
- [Projects](#projects)  
- [Conferences & Workshops](#conferences--workshops)  
- [Research Groups](#research-groups)  
- [Companies & Organizations](#companies--organizations)  
- [Contributing](#contributing)  

## Introduction  

Embodied AI represents a paradigm shift in artificial intelligence research, emphasizing the importance of physical or virtual embodiment in developing intelligent systems. This list aims to provide a comprehensive collection of resources for researchers, developers, and enthusiasts in the field.  

### What is Embodied AI?  
- The integration of perception, action, and learning in physical or simulated environments  
- Focus on interactive and experiential learning  
- Emphasis on real-world or realistic virtual environment interaction  

## Getting Started  

### Essential Concepts  
- Sensorimotor Learning  
- Active Perception  
- Environmental Interaction  
- Embodied Learning  
- Cognitive Development  

### Key Resources for Beginners  
- [Introduction to Embodied AI](link) - A comprehensive overview  
- [Embodied AI Tutorial](link) - Step-by-step guide  
- [Basic Concepts and Principles](link) - Fundamental theories  

## Papers  

### Survey Papers  
- [Pfeifer, Rolf, and Fumiya Iida. "Embodied artificial intelligence: Trends and challenges." Lecture notes in computer science (2004): 1-26.](https://people.csail.mit.edu/iida/papers/PfeiferIidaEAIDags.pdf) - Description (2004)  
- [马伟霞](www.baidu.com) - Description (Year)  

### Foundational Papers  
- [Title](link) - Description (Year)  
- [Title](link) - Description (Year)  

### Recent Advances  
- [Title](link) - Description (Year)  
- [Title](link) - Description (Year)  

## Software & Tools  

### Simulation Platforms  
- [Platform Name](link) - Description  
- [Platform Name](link) - Description  

### Development Frameworks  
- [Framework Name](link) - Description  
- [Framework Name](link) - Description  

### Libraries  
- [Library Name](link) - Description  
- [Library Name](link) - Description  

## Datasets  

### Benchmark Datasets  
- [Dataset Name](link) - Description  
- [Dataset Name](link) - Description  

### Research Datasets  
- [Dataset Name](link) - Description  
- [Dataset Name](link) - Description  

## Courses & Tutorials  

### Online Courses  
- [Building and Working in Environments for Embodied AI](https://ai-workshops.github.io/building-and-working-in-environments-for-embodied-ai-cvpr-2022/) - Simon Fraser University, Angel Xuan Chang
- [AI-Enabled Robotics Class](https://pupper-independent-study.readthedocs.io/en/latest/index.html) - tanford Robotics Independent Study, Jaden Clark


### Video Tutorials  
- [CS539 - Embodied AI](https://web.engr.oregonstate.edu/~leestef/courses/2019/fall/cs539.html) - We will read and analyze the strengths and weaknesses of recent research papers on a variety of topics in embodied AI and identify open research questions. 

### Books & Reading Materials  
- [Multimodal Large Models: The New Paradigm of Artificial General Intelligence](https://hcplab-sysu.github.io/Book-of-MLM/) - Yang Liu, Liang Lin, 2024
- [Controlling Robots Via Large Language Models](https://www.cs.cornell.edu/courses/cs4756/2023sp/assets/slides_notes/lec26_slides.pdf) -Sanjiban Choudhury, 2023

## Projects  

### Open Source Projects  
- [CogAgent: Visual Expert for Pretrained Language Models](https://github.com/THUDM/CogVLM?tab=readme-ov-file) - CogAgent is an open-source visual language model improved based on CogVLM.
- [All Robots in One: A New Standard and Unified Dataset for Versatile, General-Purpose Embodied Agents](https://imaei.github.io/project_pages/ario/) - we introduce ARIO (All Robots In One), a new data standard that enhances existing datasets by offering a unified data format, comprehensive sensory modalities, and a combination of real-world and simulated data.
- [Language Guided Generation of 3D Embodied AI Environments](https://github.com/allenai/Holodeck) - Holodeck is based on AI2-THOR.
- [Embodied CLIP](https://github.com/allenai/embodied-clip) - Producing an agent capable of zero-shot object navigation that can navigate to objects that were not used as targets during training.

### Research Projects  
- [ProAgent: From Robotic Process Automation to Agentic Process Automation](https://github.com/OpenBMB/ProAgent) - Tsinghua University, this paper introduces (APA), a groundbreaking automation paradigm using LLM-based agents for advanced automation by offloading the human labor to agents associated with construction and execution.
- [OpenButler](https://zhuanlan.zhihu.com/p/684845130) - BTH Group, 本项目是由BTH Group研究团队开源的一个轻量化具身智能项目。项目采用斯坦福开源的ACT模仿学习技术作为核心，面向实物样机部署对其软硬件接口统一封装，并结合数字虚拟机器人可以实现示教数据采集与对神经网络的快速验证，本框架可以脱离实物样机进行开发，同时采用了ROS标准数据接口可快速部署至任意的机器人系统中。

### Demo Applications  
- [Do As I Can, Not As I Say: Grounding Language in Robotic Affordances](https://github.com/google-research/google-research/tree/master/saycan) - 本文主要提出了一种将语言模型转化为机器指令的方法，大规模语言模型的能力可以帮助分解语义从而得到足够的可能，然后通过强化学习训练一个价值函数来判断可能的价值，最终指导机器人去找到海绵、拿起海绵、找到你、放下海绵、结束。
- [Bluefin-21](https://gdmissionsystems.com/products/underwater-vehicles/bluefin-21-autonomous-underwater-vehicle) -The Bluefin-21 is a highly modular autonomous Unmanned Underwater Vehicle (UUV) able to carry multiple sensors and payloads at once. It boasts a high energy capacity that enables extended operations even at the greatest depths. The Bluefin-21 has immense capability but is also flexible enough to operate from various ships of opportunity worldwide.
- [Roomba](https://www.irobot.cn/roomba/index.html) - Roomba是iRobot公司开发的家用扫地机器人，采用具身智能技术进行家庭清洁。通过传感器感知房间布局，能够自主规划清洁路径。具备避障能力，能够识别家具和其他障碍物。广泛应用于家庭清洁，提升了用户的生活便利性。
- [ANYmal](https://www.anybotics.com/robotics/anymal/) - ANYmal是由瑞士联邦理工学院（ETH Zurich）开发的四足机器人，专为在复杂地形中导航而设计。具备高度的灵活性和适应能力，能够在崎岖不平的环境中移动。具备高度的灵活性和适应能力，能够在崎岖不平的环境中移动。配备多种传感器（如激光雷达、摄像头等），能够进行环境感知和自主导航。主要用于工业检查、搜索与救援任务，以及在危险环境中的操作。
- [Optimus](https://www.tesla.com/AI) - 在特斯拉召开2023年年度股东大会上，发布的Optimus人形机器人（也称为“特斯拉机器人”）是具身智能人形态机器人的一个重要实例。马斯克表示，这款机器人将具备高度的自主性，能够在工厂中执行多种任务，并预计未来每个家庭可能都会拥有多个这样的机器人。特斯拉的机器人展示了自主识别和纠正错误的能力，例如在搬运物体时能够自主拾起并放置物品，这表明其具备一定的智能决策能力,特斯拉在机器人领域的进展不仅体现在硬件上，还包括软件的重大升级，使机器人能够通过观看视频学习和模仿人类的行为，提升其灵活性和适应性。

## Conferences & Workshops  

### Major Conferences  
- [The Fifth Annual Embodied AI Workshop](https://embodied-ai.org/) - Tuesday, June 18 from 8:50am to 5:30pm Pacific, 2024, Seattle Convention Center
- [RoboTHOR: An Open Simulation-to-Real Embodied AI Platform](https://openaccess.thecvf.com/content_CVPR_2020/papers/Deitke_RoboTHOR_An_Open_Simulation-to-Real_Embodied_AI_Platform_CVPR_2020_paper.pdf) - 2020
- [Habitat: A Platform for Embodied AI Research](https://openaccess.thecvf.com/content_ICCV_2019/html/Savva_Habitat_A_Platform_for_Embodied_AI_Research_ICCV_2019_paper.html) - 2019

### Workshops & Symposiums  
- [Retrospectives on the Embodied AI Workshop](https://arxiv.org/pdf/2210.06849) - Associated Conference, 13 Oct 2022
- [Workshop on Embodied Intelligence with Large Language Models In Open City Environment](https://openreview.net/pdf?id=zIybgEio8Y) - Associated Conference,  03 Dec 2024

## Research Groups  

### Academic Research Groups  
- [具身智能与机器人研究中心](https://www.ai.pku.edu.cn/kxyj1/tyrgznyjs/jsznyjqryjzx.htm) - 北京大学, 具身智能与机器人
- [清华大学智能产业研究院](https://air.tsinghua.edu.cn/info/1007/2354.htm) - 清华大学, 人工智能，智能产业

### Industry Research Labs  
- [Facebook AI Research](https://about.fb.com/news/2023/11/decade-of-advancing-ai-through-open-research/) - Facebook, AI
- [NVIDIA Isaac Lab](https://developer.nvidia.com/isaac/lab) - NVIDIA, robot learning

## Companies & Organizations  

### Companies Working on Embodied AI  
- [iRobot](https://www.irobot.cn/) - 扫地机器人

### Organizations & Foundations  
- [深圳市人工智能与机器人研究院](https://airs.cuhk.edu.cn/article/1124) - AIRS致力于开创一个集政府引导、国际联合、大学依托、企业合作、创投融资、双创孵化于一体的研究机构模式，重点开展AI与机器人的基础、共性、关键技术研究与突破，包括AI、具身智能和机器人在医疗、工业、可持续发展等方面的应用，为国家战略产业培养国际化人才，赋能企业创新，助力产业孵化，服务社会高质量发展
- [多智能体与具身智能研究所](https://imaei.github.io/) - 研究所以人工智能前沿技术探索、以及原创技术引领产业发展为导向，依托鹏城云脑、中国算力网等鹏城实验室主导研发的自主可控基础设施，重点突破智能体视角下的多模态感知与生成、智能体任务生成与规划、多智能体的通讯协作与联合决策、具身智能体的控制与人机共融、智能体评测机制与体系等几大方向开展研究，致力于打造多智能体协同与仿真训练平台、云端协同具身多模态大模型等通用基础平台。

## Contributing  

### How to Contribute  
1. Fork the repository  
2. Create a new branch: `git checkout -b add-new-resource`  
3. Add your changes following the formatting guidelines  
4. Submit a pull request  

### Contribution Guidelines  
- Ensure the resource is relevant to Embodied AI  
- Provide a clear description  
- Include necessary links and references  
- Follow the existing format  
- Verify links are working  
- Add new resources to the appropriate section  

### Quality Standards  
- Resources should be actively maintained  
- Content must be high quality and informative  
- Commercial resources should be clearly marked  
- Avoid duplicates  

## License  

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.  

## Acknowledgments  

Special thanks to all contributors who have helped to build and maintain this awesome list!  

---  

## Star History  

[![Star History Chart](https://api.star-history.com/svg?repos=tinyEmbodiedAI/awesome-embodied-ai&type=Date)](https://star-history.com/#tinyEmbodiedAI/awesome-embodied-ai&Date)  

## Contact  

For questions, suggestions, or issues, please:  
- Open an issue  
- Submit a pull request  
- Contact maintainers: [maintainer@email.com](mailto:jqwang16@icloud.com)  

---  

If you find this resource helpful, please consider giving it a ⭐️ to help others discover it!
